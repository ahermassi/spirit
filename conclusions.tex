% (C) 2016 Jean Nassar. Some Rights Reserved
% Except where otherwise noted, this work is licensed under the Creative Commons Attribution-ShareAlike License, version 4
% Conclusions
\chapter{Discussion}
\gls{spirit} significantly improved the accuracy (95\% credible), and reduces the \gls{rmse} in \sym{posx} and \sym{posy}.
However, a downside of this was the tasks taking longer (81.5\% credible), and having a longer path length in general (86.1\% credible).

It appears that the duration converges as time goes on, but more research is needed.
Meanwhile, the path length increase seems to be caused primarily in the \sym{posy} direction, and then mainly in people for whom it was the first time flying with \gls{spirit}.
During their second runs, they tend to do about as well as people using the onboard camera who have also had one attempt.

All \gls{spirit} subjects confirmed that they were able to see the target, and their relative position horizontally, but many had difficulty estimating their location in \sym{posy}.
This is shown in Figure \ref{fig:distrubtion_spirit}.

People using the onboard view had a strong backward bias, with the 95\% \gls{hpd} falling completely outside the target area.
They also have a large standard deviation in \sym{posx}, despite having a mean that is close to the centre.
The distribution was also slightly semicurcular.
Some students have commented that they were using a pole holding the motion capture cameras as a marker, and were orienting around that.
These results may be due to the fact that the target disappears earlier when using the camera, and with no depth perception, the user has to guess their way through, and they tend to be more cautious than when they can see the target.

People using \gls{spirit} had a rightward bias, with the 95\% \gls{hpd} falling completely to the right of 0).
However, it also remains entirely on the target.
On the other hand, while the mean of the \sym{posy} error is above the target, its large standard deviation means that the users can be off-target by up to about one target length.
%TODO Target size mention

A strategy that emerged among some people was to move in from the side, where they were able to use perspective to estimate the position more accurately.
By extending the lines of the target upwards, and moving the drone in a specific manner, they became much better.


A large reduction in the \gls{tlx} score was observed.
Analysis of the components show that the scores decreased across the board, with large improvements in effort and frustration, as well as performance.
Similarly, according to the survey, there was a large increase in position awareness and control, both absolute and relative to the target.

Users report that the onboard view was taxing because the update rate was very slow.
They had to keep stopping the drone and move forward in short bursts so that they did not hit their surroundings.
On the other hand, with \gls{spirit}, they liked that the update rate was high, and it felt safer to control, notwithstanding concerns about depth.

\chapter{Conclusions}
\label{ch:conclusion}
\gls{spirit}, a novel robotics teleoperation system which overlays the current position and orientation of a vehicle onto previously captured images.
It works even in a low-throughput environment where video data might suffer.

Experiments were conducted to study the efficacy at increasing accuracy while decreasing time and wasted movements.
Participants were tasked with flying a drone to a location above a known target while using the proposed system, and comparing the results with those obtained by flying with a slowed-down onboard camera.

\gls{spirit} improved accuracy and reduced error, but users took a slightly longer time and took a slightly longer path.
There are indicators, however, that convergence with the onboard group does occur for both these factors, and this may merit further study.

Users had a reduced cognit


\chapter{Future work}
% TODO: Discuss different groups?
Several suggestions for improving the functionality of \gls{spirit} are presented here.
They have been drawn from personal experience as well as user suggestions.

The user experience may be improved if zoom functionality is added.
That way, the size of the drone model would remain relatively constant, while the background changes, even with the same image as its base.
This was present in the version of \gls{spir} shown in \cite{ito2008}.

Similarly, it might be useful to always keep the horizon horizontal and tilt the image by the amount the drone was tilted when the frame was captured, as was implemented by Hing et al.\cite{hing2009}
Extending it to all three Eulerian axes would allow, for instance, the pitch to be used more effectively.
This would be useful with modern drones, which often use gimbals.

It was discovered that depth perception was difficult when using \gls{spirit}.
It might be possible to improve this by showing a shadow where the ground should be.
If distance estimation is used, it could be used in a wide variety of environments.
Another potential solution is to use binocular cameras and have the user wear a head-mounted display.
In this case, movement around fixed obstacles should also be feasible.
% TODO: LSD-SLAM. See Michael's email.

Many users mentioned that the motion capture pole near the target was used as a marker to help orient the drone when flying using the onboard view.
They felt that it provided an unfair advantage, and that other methods of placing the motion capture camera might make the task much more difficult.
Removing the pole might give a fairer comparison with \gls{spirit}

Performance can be improved by replacing \gls{pygame} with \gls{pyqt5}.
This might also solve the problem with the sound system not being able to initialize, which had previously necessitated restarts.

Finally, using an $n$-tree (an octree, or, its extension, a hextree), to prune the search space might enable a bigger buffer.
A hextree would be implemented using \sym{posx}, \sym{posy}, and \sym{posz} positions, as well as yaw.
Higher dimensions for gimballed platforms would also include pitch and roll.
Instead of evaluating the entire buffer, only the frames in which the drone would have been visible in the first place can be checked, thereby significantly reducing processing time.

% TODO: What about rotation? Camera disappears.
% TODO: Free the drone! Don't use mocap.
